{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "***[Dataset: Delicious]***\n",
      "--------------------------\n",
      "POS Accuracy: 64.63% (3618/5598)\n",
      "NEG Accuracy: 43.75% (2449/5598)\n",
      "--------------------------\n",
      "Difference: 20.88%\n",
      "\n",
      "--------------------------\n",
      "***[Dataset: Ciao]***\n",
      "--------------------------\n",
      "Rating: 1 | Acc: 61.53%% (3991/6486)\n",
      "Rating: 2 | Acc: 51.43%% (3512/6829)\n",
      "Rating: 3 | Acc: 55.49%% (8414/15162)\n",
      "Rating: 4 | Acc: 52.27%% (20220/38687)\n",
      "Rating: 5 | Acc: 55.46%% (36774/66304)\n",
      "--------------------------\n",
      "POS Accuracy: 54.63% (72911/133468)\n",
      "NEG Accuracy: 38.42% (51281/133468)\n",
      "--------------------------\n",
      "Difference: 16.21%\n",
      "\n",
      "--------------------------\n",
      "***[Dataset: Bookcrossing]***\n",
      "--------------------------\n",
      "Rating: 1 | Acc: 59.75%% (380/636)\n",
      "Rating: 2 | Acc: 58.44%% (606/1037)\n",
      "Rating: 3 | Acc: 55.19%% (1245/2256)\n",
      "Rating: 4 | Acc: 53.77%% (1831/3405)\n",
      "Rating: 5 | Acc: 52.73%% (10283/19500)\n",
      "Rating: 6 | Acc: 55.2%% (8268/14977)\n",
      "Rating: 7 | Acc: 56.16%% (18130/32283)\n",
      "Rating: 8 | Acc: 57.23%% (26714/46676)\n",
      "Rating: 9 | Acc: 58.42%% (19133/32749)\n",
      "Rating: 10 | Acc: 58.83%% (21395/36370)\n",
      "--------------------------\n",
      "POS Accuracy: 55.42% (313673/566036)\n",
      "NEG Accuracy: 35.57% (201338/566036)\n",
      "--------------------------\n",
      "Difference: 19.85%\n",
      "\n",
      "--------------------------\n",
      "***[Dataset: Cellphone]***\n",
      "--------------------------\n",
      "Rating: 1.0 | Acc: 76.74%% (11560/15063)\n",
      "Rating: 2.0 | Acc: 76.38%% (9267/12132)\n",
      "Rating: 3.0 | Acc: 75.77%% (17407/22973)\n",
      "Rating: 4.0 | Acc: 75.26%% (32381/43025)\n",
      "Rating: 5.0 | Acc: 75.42%% (91158/120865)\n",
      "--------------------------\n",
      "POS Accuracy: 75.57% (161773/214058)\n",
      "NEG Accuracy: 31.96% (68411/214058)\n",
      "--------------------------\n",
      "Difference: 43.62%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle as pkl\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "\n",
    "def getuserCache(df):\n",
    "    userCache = {}\n",
    "    for uid in df.uid.unique():\n",
    "        items = df.loc[df.uid == uid]['iid'].values.tolist()\n",
    "        userCache[uid] = items\n",
    "\n",
    "    return userCache\n",
    "    \n",
    "def getitemCache(df):\n",
    "    itemCache = {}\n",
    "    for iid in df.iid.unique():\n",
    "        users = df.loc[df.iid == iid]['uid'].values.tolist()\n",
    "        itemCache[iid] = users\n",
    "\n",
    "    return itemCache\n",
    "\n",
    "def dist(a,b,norm):\n",
    "    dist = np.linalg.norm((a-b),norm)\n",
    "    \n",
    "    return dist\n",
    "\n",
    "datasets = ['delicious','ciao','bookcrossing','cellphone']\n",
    "for dataset in datasets:\n",
    "    print(\"--------------------------\")\n",
    "    print(\"***[Dataset: %s]***\" %dataset.title())\n",
    "    totalFile = pd.read_csv('data/'+dataset+'/ratings.dat',sep=\"\\t\",usecols=[0,1],names=['uid','iid'],header=0)\n",
    "    total_uids = sorted(totalFile.uid.unique())\n",
    "    total_iids = sorted(totalFile.iid.unique())\n",
    "\n",
    "    trainFile = pd.read_csv('data/'+dataset+'/LOOTrain.dat',sep=\"\\t\",usecols=[0,1],names=['uid','iid'],header=0)\n",
    "    train_uids = sorted(trainFile.uid.unique())\n",
    "    train_iids = sorted(trainFile.iid.unique())\n",
    "\n",
    "    userCache = getuserCache(trainFile)\n",
    "    itemCache = getitemCache(trainFile)\n",
    "\n",
    "\n",
    "\n",
    "    root = \"data/\"+dataset  \n",
    "    # Decide data type\n",
    "    df_data = pd.read_csv(root+'/u.data',sep=\"\\t\")\n",
    "    if len(df_data.columns) == 3:\n",
    "        initial_header = ['uid','iid','rating']\n",
    "    else:\n",
    "        initial_header = ['uid','iid']\n",
    "\n",
    "    # Read data\n",
    "    df_data = pd.read_csv(root+'/u.data',sep=\"\\t\",names=initial_header)\n",
    "    if len(df_data.columns) == 3:\n",
    "        ratings_set = sorted(df_data.rating.unique().tolist())\n",
    "    df_data = df_data.drop_duplicates(['uid','iid']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # Remove uids less than numThreshold\n",
    "    sr_uid = df_data['uid'].value_counts()\n",
    "    df_count_uid = pd.DataFrame({'uid': sr_uid.index, 'count': sr_uid.values})\n",
    "    filtered_uid = df_count_uid.loc[(5 <= df_count_uid['count'])].uid\n",
    "    df_data = df_data.loc[df_data['uid'].isin(filtered_uid)].reset_index(drop=True)\n",
    "\n",
    "    sr_iid = df_data['iid'].value_counts()\n",
    "    df_count_iid = pd.DataFrame({'iid': sr_iid.index, 'count': sr_iid.values})\n",
    "    filtered_iid = df_count_iid.loc[(5 <= df_count_iid['count'])].iid\n",
    "    df_data = df_data.loc[df_data['iid'].isin(filtered_iid)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    sr_uid = df_data['uid'].value_counts()\n",
    "    df_count_uid = pd.DataFrame({'uid': sr_uid.index, 'count': sr_uid.values})\n",
    "    filtered_uid = df_count_uid.loc[(3 <= df_count_uid['count'])].uid\n",
    "    df_data = df_data.loc[df_data['uid'].isin(filtered_uid)].reset_index(drop=True)\n",
    "\n",
    "    # map uids and iids from index 0\n",
    "    unique_uids = df_data.uid.unique()\n",
    "    unique_iids = df_data.iid.unique()\n",
    "\n",
    "    uid_map = dict()\n",
    "    for idx, uid in enumerate(unique_uids):\n",
    "        uid_map[uid] = idx    \n",
    "\n",
    "    iid_map = dict()\n",
    "    for idx, iid in enumerate(unique_iids):\n",
    "        iid_map[iid] = idx\n",
    "\n",
    "    df_data['uid'] = df_data['uid'].map(uid_map)\n",
    "    df_data['iid'] = df_data['iid'].map(iid_map)\n",
    "\n",
    "    df_data = df_data.sort_values(['uid','iid']).reset_index(drop=True)\n",
    "\n",
    "    # TransCF\n",
    "    userEmbedding_TransCF = pkl.load(open('model/userEmbedding_TransCF_'+dataset+'.pkl'))\n",
    "    itemEmbedding_TransCF = pkl.load(open('model/itemEmbedding_TransCF_'+dataset+'.pkl'))\n",
    "\n",
    "\n",
    "    userNeighborEmbedding_TransCF = np.zeros((len(total_uids),128))\n",
    "    for uid in train_uids:\n",
    "        neighborItems = userCache[uid]\n",
    "        neighborItems_embeddings = np.mean(itemEmbedding_TransCF[neighborItems],axis=0).tolist()\n",
    "        userNeighborEmbedding_TransCF[uid,:] = neighborItems_embeddings\n",
    "\n",
    "    itemNeighborEmbedding_TransCF = np.zeros((len(total_iids),128))\n",
    "    for iid in train_iids:\n",
    "        neighborUsers = itemCache[iid]\n",
    "        neighborUsers_embeddings = np.mean(userEmbedding_TransCF[neighborUsers],axis=0).tolist()\n",
    "        itemNeighborEmbedding_TransCF[iid,:] = neighborUsers_embeddings\n",
    "\n",
    "    userNeighborEmbedding_TransCF = np.array(userNeighborEmbedding_TransCF)\n",
    "    itemNeighborEmbedding_TransCF = np.array(itemNeighborEmbedding_TransCF)\n",
    "\n",
    "    pos_cnt = 0\n",
    "    neg_cnt = 0\n",
    "    total_cnt = 0\n",
    "\n",
    "    if len(initial_header) == 3:\n",
    "        per_rating_correct_cnt = [0] * len(ratings_set)\n",
    "        per_rating_total_cnt = [0] * len(ratings_set)\n",
    "\n",
    "    for uid in train_uids:\n",
    "        iids = trainFile.loc[trainFile.uid == uid]['iid'].values.tolist()\n",
    "        tmp_iids = totalFile.loc[totalFile.uid == uid]['iid'].values.tolist()\n",
    "        if len(initial_header) == 3:\n",
    "            ratings = df_data.loc[df_data.uid == uid][:-2]['rating'].values.tolist()\n",
    "\n",
    "        neg_iids = list(set(train_iids).difference(set(tmp_iids)))\n",
    "        neg_iids = np.random.choice(neg_iids,len(iids))\n",
    "\n",
    "        user = userEmbedding_TransCF[uid].reshape(1,-1)\n",
    "        items = itemEmbedding_TransCF[iids]\n",
    "        neg_items = itemEmbedding_TransCF[neg_iids]\n",
    "\n",
    "        neighborUserEmbedding = userNeighborEmbedding_TransCF[uid]\n",
    "\n",
    "        translated_users = []\n",
    "        for idx, iid in enumerate(iids):\n",
    "            neighborItemEmbedding = itemNeighborEmbedding_TransCF[iid]\n",
    "            translation = neighborUserEmbedding * neighborItemEmbedding\n",
    "            translated_user = user.ravel() + translation\n",
    "            translated_users.append(translated_user.tolist())\n",
    "\n",
    "        translated_users_neg = []\n",
    "        for idx, iid in enumerate(neg_iids):\n",
    "            neighborItemEmbedding = itemNeighborEmbedding_TransCF[iid]\n",
    "            translation = neighborUserEmbedding * neighborItemEmbedding\n",
    "            translated_user = user.ravel() + translation\n",
    "            translated_users_neg.append(translated_user.tolist())\n",
    "\n",
    "        translated_users = np.array(translated_users)\n",
    "        translated_users_neg = np.array(translated_users_neg)\n",
    "\n",
    "        for idx, iid in enumerate(iids):\n",
    "            if len(initial_header) == 3:\n",
    "                rat = ratings[idx]\n",
    "                if dataset != 'bookcrossing' and rat == 0:\n",
    "                    continue\n",
    "                rating_idx = ratings_set.index(rat)\n",
    "                per_rating_total_cnt[rating_idx] += 1\n",
    "\n",
    "            total_cnt+=1\n",
    "            before_dist_pos = dist(user, items[idx], 2)\n",
    "            after_dist_pos = dist(translated_users[idx], items[idx], 2)\n",
    "\n",
    "            before_dist_neg = dist(user, neg_items[idx], 2)\n",
    "            after_dist_neg = dist(translated_users_neg[idx], neg_items[idx], 2)\n",
    "\n",
    "            if before_dist_pos >= after_dist_pos:\n",
    "                pos_cnt+=1\n",
    "                if len(initial_header) == 3:\n",
    "                    per_rating_correct_cnt[rating_idx] += 1\n",
    "\n",
    "            if before_dist_neg >= after_dist_neg:\n",
    "                neg_cnt+=1\n",
    "\n",
    "\n",
    "    if len(initial_header) == 3:\n",
    "        print(\"--------------------------\")\n",
    "        for rat in ratings_set:\n",
    "            if rat == 0:\n",
    "                continue\n",
    "            idx = ratings_set.index(rat)\n",
    "            acc = per_rating_correct_cnt[idx] / float(per_rating_total_cnt[idx]) * 100\n",
    "            print(\"Rating: {} | Acc: {}%% ({}/{})\".format(rat, np.round(acc,2), per_rating_correct_cnt[idx], per_rating_total_cnt[idx]))\n",
    "    \n",
    "    pos_accuracy = (pos_cnt / float(total_cnt)) * 100\n",
    "    neg_accuracy = (neg_cnt / float(total_cnt)) * 100\n",
    "    difference = pos_accuracy - neg_accuracy\n",
    "    print(\"--------------------------\")\n",
    "    print(\"POS Accuracy: %.2f%% (%d/%d)\" %(pos_accuracy, pos_cnt, total_cnt))\n",
    "    print(\"NEG Accuracy: %.2f%% (%d/%d)\" %(neg_accuracy, neg_cnt, total_cnt))\n",
    "    print(\"--------------------------\")\n",
    "    print(\"Difference: %.2f%%\\n\" %(difference))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
