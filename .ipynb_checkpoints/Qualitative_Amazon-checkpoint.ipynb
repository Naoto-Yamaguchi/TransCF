{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "***\n",
    "## Reading data and preparing vectors\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cellphone, Thres: 0.5, Perplexity: 30, numSubset: 200\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6793d4c87226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_uids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_iids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_uids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserCache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemCache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muid_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mdf_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_map_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedIid_mappedCat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractCategory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "import gzip\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle as pkl\n",
    "import operator\n",
    "import scipy.io as sio\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from data_preprocess import *\n",
    "np.random.seed(23254)\n",
    "\n",
    "dataset = 'cellphone'\n",
    "thres = 0.5\n",
    "perplexity = 30\n",
    "numSubset = 200\n",
    "print(\"Dataset: {}, Thres: {}, Perplexity: {}, numSubset: {}\".format(dataset, thres, perplexity, numSubset))\n",
    "\n",
    "df_data, total_uids, total_iids, train_uids, train_iids, userCache, itemCache, uid_map, iid_map = readData(dataset)\n",
    "\n",
    "df_data, cat_map, category_map_inv, mappedIid_mappedCat, category_map = extractCategory(dataset, df_data, iid_map)\n",
    "\n",
    "df_data['cat'] = df_data['iid'].map(cat_map)\n",
    "df_data['uid'] = df_data['uid'].map(uid_map)\n",
    "df_data['iid'] = df_data['iid'].map(iid_map)\n",
    "df_data = df_data.sort_values(['uid','iid']).reset_index(drop=True)\n",
    "\n",
    "itemEmbedding_CML, itemEmbedding_TransCF, translation_vecs_TransCF, translation_vecs_CML, translation_vecs_TransCF_emb, ratings, translation_vecs_TransCF_categories, translation_vecs_CML_categories, translation_vecs_TransCF_emb_categories, categories = getEmbeddings(dataset, df_data, total_uids, total_iids, train_uids, train_iids, userCache, itemCache)\n",
    "\n",
    "translation_vecs_TransCF, translation_vecs_CML, translation_vecs_TransCF_emb, ratings = preprocessRatings(translation_vecs_TransCF, translation_vecs_CML, translation_vecs_TransCF_emb, ratings)\n",
    "translation_vecs_TransCF_categories, translation_vecs_CML_categories, translation_vecs_TransCF_emb_categories, categories, itemEmbedding_CML, itemEmbedding_TransCF, categories_emb = preprocessCategories(dataset, itemEmbedding_CML, itemEmbedding_TransCF, translation_vecs_TransCF_categories, translation_vecs_CML_categories, translation_vecs_TransCF_emb_categories, categories, category_map_inv, mappedIid_mappedCat, category_map)\n",
    "\n",
    "\n",
    "# filter for translation vectors\n",
    "## Ratings\n",
    "translation_vecs_TransCF, translation_vecs_CML, translation_vecs_TransCF_emb, ratings = balanceData(translation_vecs_TransCF, translation_vecs_CML, translation_vecs_TransCF_emb, ratings, False)\n",
    "## Categories\n",
    "translation_vecs_TransCF_categories, translation_vecs_CML_categories, translation_vecs_TransCF_emb_categories, categories = balanceData(translation_vecs_TransCF_categories, translation_vecs_CML_categories, translation_vecs_TransCF_emb_categories, categories, True)\n",
    "\n",
    "# filter categories for embeddings\n",
    "itemEmbedding_TransCF, itemEmbedding_CML, categories_emb = balanceData_emb(itemEmbedding_TransCF, itemEmbedding_CML, categories_emb)\n",
    "\n",
    "print(\"***Done Preparing Data***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "***\n",
    "## Classification\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Classification (Rating and Category)\n",
    "def scoring(clf, translation_vecs_CML, translation_vecs_TransCF_emb, translation_vecs_TransCF, labels, rand=False):\n",
    "    \n",
    "    if rand == True:\n",
    "        scores = cross_val_score(clf, translation_vecs_CML, labels, cv=5, n_jobs=-1)\n",
    "        print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n",
    "    else:\n",
    "        scores = cross_val_score(clf, translation_vecs_CML, labels, cv=5, n_jobs=-1)\n",
    "        print(\"[CML] Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n",
    "        if len(translation_vecs_TransCF_emb) != 0:\n",
    "            scores = cross_val_score(clf, translation_vecs_TransCF_emb, labels, cv=5, n_jobs=-1)\n",
    "            print(\"[TransCF_emb] Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n",
    "        scores = cross_val_score(clf, translation_vecs_TransCF, labels, cv=5, n_jobs=-1)\n",
    "        print(\"[TransCF] Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "        \n",
    "def classification(translation_vecs_CML, translation_vecs_TransCF_emb, translation_vecs_TransCF, labels):        \n",
    "    print(\"===Random Guess===\")\n",
    "    clf = DummyClassifier()\n",
    "    scoring(clf, translation_vecs_CML, translation_vecs_TransCF_emb, translation_vecs_TransCF, labels, True)\n",
    "\n",
    "\n",
    "    print(\"===Random Forest===\")\n",
    "    clf = RandomForestClassifier(n_estimators=300, n_jobs=-1)\n",
    "    scoring(clf, translation_vecs_CML, translation_vecs_TransCF_emb, translation_vecs_TransCF, labels)\n",
    "\n",
    "    \n",
    "# Classify ratings\n",
    "print(\"[Classification for ratings]\")\n",
    "classification(translation_vecs_CML, translation_vecs_TransCF_emb, translation_vecs_TransCF, ratings)\n",
    "\n",
    "# Classify categories\n",
    "print(\"\\n[Classify Categories for translation vectors]\")\n",
    "classification(translation_vecs_CML_categories, translation_vecs_TransCF_emb_categories, translation_vecs_TransCF_categories, categories)\n",
    "print(\"\\n[Classify Categories using item embedding vectors]\")\n",
    "classification(itemEmbedding_CML, [], itemEmbedding_TransCF, categories_emb)\n",
    "print(\"***Done Classifications***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "***\n",
    "## Filtering\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "def classification_for_filtering(X, y):\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    new_X = []\n",
    "    new_y = []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        clf = RandomForestClassifier(n_estimators=300, n_jobs=-1).fit(X_train, y_train)\n",
    "        \n",
    "        prob = clf.predict_proba(X_test)\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        \n",
    "        # Filter only correct ones\n",
    "        correct_idx = np.equal(y_test, y_test_pred)\n",
    "        X_test = X_test[correct_idx]\n",
    "        y_test = y_test[correct_idx]\n",
    "        prob = prob[correct_idx]\n",
    "        \n",
    "        threshold = np.amax(prob, axis=1)\n",
    "        \n",
    "        X_test = X_test[threshold>thres].tolist()\n",
    "        y_test = y_test[threshold>thres].tolist()\n",
    "        \n",
    "        new_X += X_test\n",
    "        new_y += y_test\n",
    "    \n",
    "    new_X = np.array(new_X)\n",
    "    new_y = np.array(new_y)\n",
    "    \n",
    "    return new_X, new_y\n",
    "\n",
    "\n",
    "# Filtering candidates for plotting by classification\n",
    "# Trans\n",
    "translation_vecs_TransCF_categories, categories_TransCF = classification_for_filtering(translation_vecs_TransCF_categories, categories)\n",
    "translation_vecs_TransCF_categories, _, _, categories_TransCF = balanceData(translation_vecs_TransCF_categories, [], [], categories_TransCF, cat=True)\n",
    "\n",
    "# CML\n",
    "translation_vecs_CML_categories, categories_CML = classification_for_filtering(translation_vecs_CML_categories, categories)\n",
    "translation_vecs_CML_categories, _, _, categories_CML = balanceData(translation_vecs_CML_categories, [], [], categories_CML, cat=True)\n",
    "print(\"***Done filtering for TSNE***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "***\n",
    "## t-SNE Plotting\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot TSNE\n",
    "print(\"Start TSNE\")\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "# TSNE Categories\n",
    "X_TSNE_TransCF = TSNE(perplexity=perplexity, n_jobs=8).fit_transform(translation_vecs_TransCF_categories)\n",
    "X_TSNE_CML = TSNE(perplexity=perplexity, n_jobs=8).fit_transform(translation_vecs_CML_categories)\n",
    "print(\"Done TSNE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "colormap = 'Paired'\n",
    "\n",
    "def select_subset(n, X_heatmap, X_TSNE, y):\n",
    "    X_small_TSNE = []\n",
    "    X_small_heatmap = []\n",
    "    y_small = []\n",
    "    \n",
    "    minVal = 10000000\n",
    "    # get min num val\n",
    "    for elem in np.unique(y):\n",
    "        tmp = np.sum(y == elem)\n",
    "        if tmp < minVal:\n",
    "            minVal = tmp\n",
    "            \n",
    "    if n > minVal:\n",
    "        n= minVal\n",
    "    \n",
    "    for elem in np.unique(y):\n",
    "        idxs = np.random.choice(np.where((y == elem))[0], n)\n",
    "        X_small_TSNE += X_TSNE[idxs].tolist()\n",
    "        X_small_heatmap += X_heatmap[idxs].tolist()\n",
    "        y_small += y[idxs].tolist()\n",
    "    \n",
    "    cat_dict = dict()\n",
    "    for x,y in zip(X_small_heatmap,y_small):\n",
    "        cat_dict.setdefault(y,[]).append(x)\n",
    "        \n",
    "    X_small = np.array(X_small_TSNE)    \n",
    "    y_small = np.array(y_small)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_small, y_small, n, cat_dict\n",
    "\n",
    "def plot_result(method, xs, ys, labels, numSamples): \n",
    "    lab_idx = dict()\n",
    "    for idx, lab in enumerate(set(labels)):\n",
    "        lab_idx[category_map_inv[lab]] = idx\n",
    "        \n",
    "    cmap = plt.get_cmap(colormap)\n",
    "    colors = cmap(np.linspace(0, 1, len(set(labels))))\n",
    "    \n",
    "    lst = [0]*len(set(labels))\n",
    "    fig = plt.figure(edgecolor='black')\n",
    "    for x,y,lab in zip(xs,ys,labels):\n",
    "        plt.scatter(x,y,s=8,c=colors[lab_idx[category_map_inv[lab]]],label=category_map_inv[lab] if lst[lab_idx[category_map_inv[lab]]] == 0 else \"\", alpha=0.8)\n",
    "        lst[lab_idx[category_map_inv[lab]]] = 1\n",
    "    plt.legend(fontsize=6,ncol=5,edgecolor='black',loc='lower center')\n",
    "    \n",
    "    plt.title('Method: {}, Dataset: {}, Threshold: {}, Perplexity: {} | numSamples: {}'.format(method, dataset, thres, perplexity, numSamples),fontsize=7)\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "import os.path\n",
    "def final_plot(X, X_TSNE, y, method):\n",
    "    X_TSNE_small, y_small, numSamples, cat_dict = select_subset(numSubset, X, X_TSNE, y)\n",
    "    \n",
    "    plot_result(method, X_TSNE_small[:,0],X_TSNE_small[:,1],y_small,numSamples)\n",
    "    \n",
    "    return cat_dict\n",
    "\n",
    "cat_dict_TransCF = final_plot(translation_vecs_TransCF_categories, X_TSNE_TransCF, categories_TransCF, 'TransCF')\n",
    "cat_dict_CML = final_plot(translation_vecs_CML_categories, X_TSNE_CML, categories_CML, 'CML')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "***\n",
    "## Draw Heat map\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def calc_correlation(cat_dict):\n",
    "    correlation_dict = dict()\n",
    "    already = set()\n",
    "    for cat in cat_dict.keys():\n",
    "        for cat_ in cat_dict.keys():\n",
    "            if cat_ in already:\n",
    "                continue\n",
    "            already.add(cat)\n",
    "            # print(\"Cat1: {} | Cat2: {}\".format(cat,cat_))\n",
    "            for target in cat_dict[cat]:\n",
    "                for target2 in cat_dict[cat_]:\n",
    "                    result = 1 - spatial.distance.cosine(target, target2)\n",
    "                    correlation_dict.setdefault((cat,cat_),0.0)\n",
    "                    correlation_dict[(cat,cat_)] += result\n",
    "    \n",
    "    return correlation_dict\n",
    "\n",
    "import seaborn as sns\n",
    "def draw_heatmap(result, categories, method):\n",
    "    max_ = 0\n",
    "    lst = []\n",
    "    real_cats = []\n",
    "    for cat1 in categories:\n",
    "        real_cats.append(category_map_inv[cat1])\n",
    "        tmp = []\n",
    "        for cat2 in categories:\n",
    "            try:\n",
    "                val = result[(cat1,cat2)]\n",
    "            except:\n",
    "                val = result[(cat2,cat1)]\n",
    "            if val > max_:\n",
    "                max_ = val\n",
    "            tmp.append(val)\n",
    "        lst.append(tmp)\n",
    "    \n",
    "    lst = np.array(lst) / float(max_)\n",
    "    # plot the heatmap\n",
    "    cmap = 'BuGn'\n",
    "    plt.figure()\n",
    "    sns.heatmap(lst, xticklabels=real_cats, yticklabels=real_cats, cmap=cmap,annot=True)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=360)\n",
    "    plt.title(method)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# CML\n",
    "result = calc_correlation(cat_dict_CML)\n",
    "categories = cat_dict_CML.keys()\n",
    "draw_heatmap(result,categories,\"CML\")\n",
    "\n",
    "# TransCF\n",
    "result = calc_correlation(cat_dict_TransCF)\n",
    "categories = cat_dict_TransCF.keys()\n",
    "draw_heatmap(result,categories,\"TransCF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
